{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import _pickle as pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to recluster new profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('profiles.pkl', 'rb') as f:\n",
    "    profiles_df = pickle.load(f)\n",
    "\n",
    "with open('clustered_profiles.pkl', 'rb') as f:\n",
    "    cluster_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bios</th>\n",
       "      <th>games</th>\n",
       "      <th>music</th>\n",
       "      <th>movies</th>\n",
       "      <th>jokes</th>\n",
       "      <th>Cluster #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hipster-friendly explorer. Beer trailblazer. I...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lifelong music scholar. Typical zombie evangel...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Writer. Friendly twitter scholar. Hardcore rea...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pop culture buff. Reader. Certified gamer. Web...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General organizer. Troublemaker. Certified alc...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                bios  games  music  movies  \\\n",
       "0  Hipster-friendly explorer. Beer trailblazer. I...    4.0    9.0     4.0   \n",
       "1  Lifelong music scholar. Typical zombie evangel...    6.0    5.0     9.0   \n",
       "2  Writer. Friendly twitter scholar. Hardcore rea...    7.0    5.0     2.0   \n",
       "3  Pop culture buff. Reader. Certified gamer. Web...    8.0    9.0     6.0   \n",
       "4  General organizer. Troublemaker. Certified alc...    7.0    7.0     0.0   \n",
       "\n",
       "   jokes  Cluster #  \n",
       "0    4.0          0  \n",
       "1    9.0          0  \n",
       "2    4.0          8  \n",
       "3    8.0          7  \n",
       "4    5.0          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter new profile information...\n",
      "\n",
      "Example Bio:\n",
      "Bacon enthusiast. Falls down a lot. Freelance social media fan. Infuriatingly humble introvert.\n"
     ]
    }
   ],
   "source": [
    "# Instantiating a new DF row to append later\n",
    "new_profile = pd.DataFrame(columns=profiles_df.columns)\n",
    "\n",
    "# Adding random values for new data\n",
    "for i in new_profile.columns[1:]:\n",
    "    new_profile[i] = np.random.randint(0,10,1)\n",
    "\n",
    "# Printing an user interface for inputting new values\n",
    "print(\"Enter new profile information...\\n\\nExample Bio:\\nBacon enthusiast. Falls down a lot. Freelance social media fan. Infuriatingly humble introvert.\")\n",
    "\n",
    "# Asking for new profile data\n",
    "new_profile['bios'] = input(\"Enter a Bio for yourself: \")\n",
    "\n",
    "# Indexing that new profile data\n",
    "new_profile.index = [profiles_df.index[-1] + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7866/522939601.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_cluster = profiles_df.append(new_profile)\n"
     ]
    }
   ],
   "source": [
    "new_cluster = profiles_df.append(new_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import minmaxscaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#import countVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/conda-env-movie/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## Scaling\n",
    "# Instantiating the Scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scaling the categories then replacing the old values\n",
    "df = new_cluster[['bios']].join(pd.DataFrame(scaler.fit_transform(new_cluster.drop('bios', axis=1)), columns=new_cluster.columns[1:], index=new_cluster.index))\n",
    "\n",
    "\n",
    "## Vectorizing\n",
    "# Instantiating the Vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fitting the vectorizer to the Bios\n",
    "x = vectorizer.fit_transform(df['bios'])\n",
    "\n",
    "# Creating a new DF that contains the vectorized words\n",
    "df_wrds = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Concating the words DF with the original DF\n",
    "new_df = pd.concat([df, df_wrds], axis=1)\n",
    "\n",
    "# Dropping the Bios because it is no longer needed in place of vectorization\n",
    "new_df.drop('bios', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA\n",
    "\n",
    "# Instantiating PCA\n",
    "pca = PCA()\n",
    "\n",
    "# Fitting and Transforming the DF\n",
    "df_pca = pca.fit_transform(new_df)\n",
    "\n",
    "# Finding the exact number of features that explain at least 99% of the variance in the dataset\n",
    "total_explained_variance = pca.explained_variance_ratio_.cumsum()\n",
    "n_over_99 = len(total_explained_variance[total_explained_variance>=.99])\n",
    "n_to_reach_99 = new_df.shape[1] - n_over_99\n",
    "\n",
    "# Reducing the dataset to the number of features determined before\n",
    "pca = PCA(n_components=n_to_reach_99)\n",
    "\n",
    "# Fitting and transforming the dataset to the stated number of features\n",
    "df_pca = pca.fit_transform(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tqdm\n",
    "from tqdm import tqdm\n",
    "#import AgglomerativeClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "#import silhouette_score and davies_bouldin_score\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:52<00:00,  2.94s/it]\n"
     ]
    }
   ],
   "source": [
    "# Setting the amount of clusters to test out\n",
    "cluster_cnt = [i for i in range(2, 20, 1)]\n",
    "\n",
    "# Establishing empty lists to store the scores for the evaluation metrics\n",
    "s_scores = []\n",
    "\n",
    "db_scores = []\n",
    "\n",
    "# Looping through different iterations for the number of clusters\n",
    "for i in tqdm(cluster_cnt):\n",
    "    \n",
    "    # Clustering with different number of clusters\n",
    "    hac = AgglomerativeClustering(n_clusters=i)\n",
    "    \n",
    "    hac.fit(df_pca)\n",
    "    \n",
    "    cluster_assignments = hac.labels_\n",
    "    \n",
    "    # Appending the scores to the empty lists    \n",
    "    s_scores.append(silhouette_score(df_pca, cluster_assignments))\n",
    "    \n",
    "    db_scores.append(davies_bouldin_score(df_pca, cluster_assignments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Silhouette Coefficient Score (find max score):\n",
      "Max Value:\n",
      "Cluster #    Cluster Score\n",
      "2       0.050266\n",
      "\n",
      "Min Value:\n",
      "Cluster #    Cluster Score\n",
      "4       0.028735\n",
      "\n",
      "The Davies-Bouldin Score (find minimum score):\n",
      "Max Value:\n",
      "Cluster #    Cluster Score\n",
      "4       5.233854\n",
      "\n",
      "Min Value:\n",
      "Cluster #    Cluster Score\n",
      "2       3.510583\n"
     ]
    }
   ],
   "source": [
    "def cluster_eval(y, x):\n",
    "    \"\"\"\n",
    "    Prints the scores of a set evaluation metric. Prints out the max and min values of the evaluation scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating a DataFrame for returning the max and min scores for each cluster\n",
    "    df = pd.DataFrame(columns=['Cluster Score'], index=[i for i in range(2, len(y)+2)])\n",
    "    df['Cluster Score'] = y\n",
    "    \n",
    "    print('Max Value:\\nCluster #', df[df['Cluster Score']==df['Cluster Score'].max()])\n",
    "    print('\\nMin Value:\\nCluster #', df[df['Cluster Score']==df['Cluster Score'].min()])\n",
    "    \n",
    "    \n",
    "print(\"\\nThe Silhouette Coefficient Score (find max score):\")\n",
    "cluster_eval(s_scores, cluster_cnt)\n",
    "\n",
    "print(\"\\nThe Davies-Bouldin Score (find minimum score):\")\n",
    "cluster_eval(db_scores, cluster_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running HAC\n",
    "# Instantiating HAC\n",
    "hac = AgglomerativeClustering(n_clusters=12)\n",
    "\n",
    "# Fitting\n",
    "hac.fit(df_pca)\n",
    "\n",
    "# Getting cluster assignments\n",
    "cluster_assignments = hac.labels_\n",
    "\n",
    "# Unscaling the categories then replacing the scaled values\n",
    "df = df[['bios']].join(pd.DataFrame(scaler.inverse_transform(df.drop('bios', axis=1)), columns=df.columns[1:], index=df.index))\n",
    "\n",
    "# Assigning the clusters to each profile\n",
    "df['Cluster #'] = cluster_assignments\n",
    "\n",
    "\n",
    "## Finding the Exact Cluster for our New Profile\n",
    "# Getting the Cluster # for the new profile\n",
    "profile_cluster = df.loc[new_profile.index]['Cluster #'].values[0]\n",
    "\n",
    "# Using the Cluster # to narrow down the DF\n",
    "profile_df = df[df['Cluster #']==profile_cluster].drop('Cluster #', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorizing\n",
    "# Fitting the vectorizer to the Bios\n",
    "cluster_x = vectorizer.fit_transform(profile_df['bios'])\n",
    "\n",
    "# Creating a new DF that contains the vectorized words\n",
    "cluster_v = pd.DataFrame(cluster_x.toarray(), index=profile_df.index, columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Joining the Vectorized DF to the previous DF\n",
    "profile_df = profile_df.join(cluster_v, how='left', lsuffix='_left', rsuffix='_right').drop('bios', axis=1)\n",
    "\n",
    "\n",
    "## Correlation\n",
    "# Trasnposing the DF so that we are correlating with the index(users) and finding the correlation\n",
    "corr = profile_df.T.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              bios  games  music  movies  jokes\n",
      "6825  Lifetime learner. Tech lover      8      1       1      2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bios</th>\n",
       "      <th>games</th>\n",
       "      <th>music</th>\n",
       "      <th>movies</th>\n",
       "      <th>jokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5318</th>\n",
       "      <td>General coffee practitioner. Twitter nerd. Cer...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>Food aficionado. Pop cultureaholic. Passionate...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4929</th>\n",
       "      <td>General troublemaker. Subtly charming pop cult...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4854</th>\n",
       "      <td>General troublemaker. Subtly charming pop cult...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>Extreme pop culture lover. Music expert. Bacon...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>Bacon expert. Creator. Introvert. Passionate p...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>Award-winning communicator. Evil web fanatic. ...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>Reader. Internet fanatic. Food expert. Profess...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4516</th>\n",
       "      <td>Extreme gamer. Pop culture specialist. Unapolo...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>Alcoholaholic. Coffee lover. Lifelong gamer. M...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   bios  games  music  movies  \\\n",
       "5318  General coffee practitioner. Twitter nerd. Cer...      9      2       3   \n",
       "3235  Food aficionado. Pop cultureaholic. Passionate...      8      1       0   \n",
       "4929  General troublemaker. Subtly charming pop cult...      9      1       0   \n",
       "4854  General troublemaker. Subtly charming pop cult...      9      2       0   \n",
       "2414  Extreme pop culture lover. Music expert. Bacon...      8      2       2   \n",
       "5505  Bacon expert. Creator. Introvert. Passionate p...      9      3       2   \n",
       "1866  Award-winning communicator. Evil web fanatic. ...      9      2       4   \n",
       "4149  Reader. Internet fanatic. Food expert. Profess...      9      3       3   \n",
       "4516  Extreme gamer. Pop culture specialist. Unapolo...      9      2       4   \n",
       "5471  Alcoholaholic. Coffee lover. Lifelong gamer. M...      7      0       1   \n",
       "\n",
       "      jokes  \n",
       "5318      2  \n",
       "3235      3  \n",
       "4929      3  \n",
       "4854      4  \n",
       "2414      4  \n",
       "5505      3  \n",
       "1866      4  \n",
       "4149      4  \n",
       "4516      3  \n",
       "5471      1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the Top 10 similar or correlated users to the new user\n",
    "user_n = new_profile.index[0]\n",
    "print(new_profile)\n",
    "\n",
    "# Creating a DF with the Top 10 most similar profiles\n",
    "top_10_sim = corr[[user_n]].sort_values(by=[user_n],axis=0, ascending=False)[1:11]\n",
    "\n",
    "# Displaying the Top 10\n",
    "profiles_df.loc[top_10_sim.index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env-movie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "525d54a29e46b65d9faa0908246aac2d8632898b9e02dcb70838566021b7c4c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
